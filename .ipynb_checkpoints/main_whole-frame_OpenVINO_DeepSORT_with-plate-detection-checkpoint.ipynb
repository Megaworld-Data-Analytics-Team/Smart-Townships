{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b68f9094",
   "metadata": {},
   "source": [
    "## Person and Vehicle Counter/License Plate Detector Using OpenCV and Pre-trained Intel Model by OpenVINO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a2ca2c",
   "metadata": {},
   "source": [
    "### NOTE: Work in Progress (currently includes Object Detection and Tracking)\n",
    "- Model reference: https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/person-vehicle-bike-detection-crossroad-0078"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcdf76",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d95fd973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from openvino.runtime import Core\n",
    "\n",
    "#for object tracking\n",
    "from deep_sort import preprocessing #for max suppressions\n",
    "from deep_sort import nn_matching #for setting up the association metrics\n",
    "from deep_sort.detection import Detection #for object detection\n",
    "from deep_sort.tracker import Tracker #for object tracking information\n",
    "from tools import generate_detections as gdet #feature generation encoder\n",
    "\n",
    "import imutils\n",
    "from imutils.video import VideoStream, FPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c6ce9a",
   "metadata": {},
   "source": [
    "### Load the Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d1b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 0.1\n",
    "\n",
    "# model_path = \"c:/Users/Lenard/intel/person-vehicle-bike-detection-crossroad-0078/FP16/person-vehicle-bike-detection-crossroad-0078.xml\"\n",
    "\n",
    "# #initialize inference engine\n",
    "# ie = Core()\n",
    "# #read the network and corresponding weights from file\n",
    "# detector = ie.read_model(model=model_path)\n",
    "\n",
    "# #compile the model for the CPU (you may also use GPU, MYRIAD, etc.)\n",
    "# #or let the engine choose the available device (AUTO)\n",
    "# compiled_model = ie.compile_model(model=detector, device_name=\"GPU\")\n",
    "\n",
    "# #get input and output nodes\n",
    "# input_layer = compiled_model.input(0)\n",
    "# output_layer = compiled_model.output(0)\n",
    "\n",
    "# #get input size\n",
    "# height, width = list(input_layer.shape)[2:]\n",
    "# print(\"Height: {}, Width: {}\".format(height,width))\n",
    "# print(input_layer.any_name, output_layer.any_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c87c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 300, 300, 3}\n",
      "Height: 300, Width: 300\n"
     ]
    }
   ],
   "source": [
    "# License Plate Detection\n",
    "lpd_model_path = \"c:/Users/Lenard/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106.xml\"\n",
    "\n",
    "#initialize inference engine\n",
    "ie = Core()\n",
    "#read the network and corresponding weights from file\n",
    "plate_detector = ie.read_model(model=lpd_model_path)\n",
    "\n",
    "#compile the model for the CPU (you may also use GPU, MYRIAD, etc.)\n",
    "#or let the engine choose the available device (AUTO)\n",
    "compiled_plate_d_model = ie.compile_model(model=plate_detector, device_name=\"GPU\")\n",
    "\n",
    "#get input and output nodes\n",
    "plate_d_input_layer = compiled_plate_d_model.input(0)\n",
    "plate_d_output_layer = compiled_plate_d_model.output(0)\n",
    "\n",
    "#get input size\n",
    "print(plate_d_input_layer.shape)\n",
    "plate_d_height, plate_d_width = list(plate_d_input_layer.shape)[1:3]\n",
    "print(\"Height: {}, Width: {}\".format(plate_d_height, plate_d_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36010dce",
   "metadata": {},
   "source": [
    "### Load DeepSORT Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f521810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.4 #used to determine if objects between frames are the same\n",
    "nn_budget = None #used to form a gallery for storing of features\n",
    "nms_max_overlap = 1.0 #used to avoid too many detections on the same object\n",
    "\n",
    "model_filename = './model_data/mars-small128.pb' #pretrained CNN for pedestrian tracking\n",
    "encoder = gdet.create_box_encoder(model_filename, batch_size=8) #feature generations\n",
    "\n",
    "metric = nn_matching.NearestNeighborDistanceMetric('cosine', max_cosine_distance, nn_budget) #for measuring associations\n",
    "tracker = Tracker(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c66c461",
   "metadata": {},
   "source": [
    "### Processing Results\n",
    "- List available classes and create corresponding colors. \n",
    "- In post-processing, boxes are transformed via normalization. \n",
    "- NMS will also be used to avoid overlapping detections and those that do not meet the threshold.\n",
    "- Finally, boxes and labels will be drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b574ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes of person-vehicle-bike-detection-crossroad-0078\n",
    "classes = [\"person\", \"vehicle\", \"bike\"]\n",
    "\n",
    "#map corresponding colors to classes\n",
    "colors = cv2.applyColorMap(\n",
    "    src = np.arange(0, 255, 255 / len(classes), dtype=np.float32).astype(np.uint8),\n",
    "    colormap = cv2.COLORMAP_RAINBOW,\n",
    ").squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2f074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes of license plate detection\n",
    "plate_d_classes = [\"vehicle\", \"license plate\"]\n",
    "\n",
    "#map corresponding colors to classes\n",
    "plate_d_colors = cv2.applyColorMap(\n",
    "    src = np.arange(0, 255, 255 / len(classes), dtype=np.float32).astype(np.uint8),\n",
    "    colormap = cv2.COLORMAP_RAINBOW,\n",
    ").squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e7dd637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(frame, results, thresh=0.6):\n",
    "    # size of the original frame\n",
    "    h, w = frame.shape[:2]\n",
    "    results = results.squeeze()\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    scores = []\n",
    "    ids = []\n",
    "    new_rects = []\n",
    "    for idx, label, score, xmin, ymin, xmax, ymax in results:\n",
    "        # create a box using pixel coordinates\n",
    "        boxes.append(\n",
    "            tuple(map(int, (xmin*w, ymin*h, (xmax-xmin)*w, (ymax-ymin)*h)))\n",
    "        )\n",
    "        labels.append(int(label))\n",
    "        scores.append(float(score))\n",
    "        ids.append(int(idx))\n",
    "        \n",
    "    # apply NMS (Non-Maximum Suppression) to eliminate overlapping entities\n",
    "    # this algorithm returns indices of objects to keep\n",
    "    indices = cv2.dnn.NMSBoxes(\n",
    "        bboxes=boxes, scores=scores, score_threshold=thresh, nms_threshold=0.6\n",
    "    )\n",
    "    \n",
    "    #if there are no boxes\n",
    "    if len(indices) == 0:\n",
    "        return []\n",
    "        \n",
    "    #filter detected objects\n",
    "    return [(labels[i], scores[i], boxes[i]) for i in indices.flatten()]\n",
    "\n",
    "\n",
    "def draw_boxes(detection_type, frame, boxes):\n",
    "    if detection_type == \"PVB\":\n",
    "        for label, score, box in boxes:\n",
    "            label = label-1\n",
    "            color = tuple(map(int, colors[label]))\n",
    "            #draw box\n",
    "            x2 = box[0] + box[2]\n",
    "            y2 = box[1] + box[3]\n",
    "            cv2.rectangle(frame, box[:2], (x2,y2), color=color, thickness=3)\n",
    "\n",
    "            #draw label\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"{classes[label]} {score:.2f}\",\n",
    "                (box[0]+10, box[1]+30),\n",
    "                cv2.FONT_HERSHEY_COMPLEX,\n",
    "                frame.shape[1]/1000,\n",
    "                color,\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "        return frame\n",
    "    elif detection_type == \"LP\":\n",
    "        for label, score, box in boxes:\n",
    "            label = label-1\n",
    "            color = tuple(map(int, plate_d_colors[label]))\n",
    "            #draw box\n",
    "            x2 = box[0] + box[2]\n",
    "            y2 = box[1] + box[3]\n",
    "            cv2.rectangle(frame, box[:2], (x2,y2), color=color, thickness=3)\n",
    "\n",
    "            #draw label\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"{plate_d_classes[label]} {score:.2f}\",\n",
    "                (box[0]+10, box[1]+30),\n",
    "                cv2.FONT_HERSHEY_COMPLEX,\n",
    "                frame.shape[1]/1000,\n",
    "                color,\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7458ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(source=0, flip=False, use_popup=False, skip_first_frames=0):\n",
    "    vid = cv2.VideoCapture(source)\n",
    "\n",
    "    #give camera time to warm up\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    processing_times = collections.deque()\n",
    "    \n",
    "    #list for historical trajectory\n",
    "    from collections import deque\n",
    "    points = [deque(maxlen=30) for _ in range(1000)]\n",
    "    time_points = [deque(maxlen=30) for _ in range(1000)]\n",
    "\n",
    "    frame_count = 0\n",
    "    \n",
    "    #for counting totals\n",
    "    person_counter = []\n",
    "    vehicle_counter = []\n",
    "\n",
    "    #for counting in hours\n",
    "    person_counter_hour = []\n",
    "    vehicle_counter_hour = []\n",
    "\n",
    "    #for storing the count of the previous hours\n",
    "    prev_hours_person_count = 0\n",
    "    prev_hours_vehicle_count = 0\n",
    "\n",
    "    #dictionary for count data\n",
    "    #define dictionary of data\n",
    "    count_dict = {'Total Persons': [0], 'Total Vehicles': [0], 'Day': [0], 'Date': [0], 'Time': [0]}\n",
    "    \n",
    "    #begin video capturing\n",
    "    while (vid.isOpened()):\n",
    "        #capture frame\n",
    "        ret, frame = vid.read()\n",
    "        \n",
    "        if frame is None:\n",
    "            print('Completed!')\n",
    "            break\n",
    "        \n",
    "        #if frame is larger than full HD, reduce size to improve performance\n",
    "        scale = 1280 / max(frame.shape)\n",
    "        if scale < 1:\n",
    "            frame = cv2.resize(\n",
    "                src=frame,\n",
    "                dsize=None,\n",
    "                fx=scale,\n",
    "                fy=scale,\n",
    "                interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "        \n",
    "        \n",
    "        # resize image to fit neural network input for person, vehicle, and bike detection\n",
    "#         input_frame = cv2.resize(\n",
    "#             frame, dsize=(width,height), interpolation=cv2.INTER_AREA\n",
    "#         )\n",
    "#         frame_rgb = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "#         #create batch of images\n",
    "#         input_frame = np.expand_dims(input_frame.transpose(2,0,1), axis=0)\n",
    "        \n",
    "        # resize image to fit neural network input for plate number detection\n",
    "        plate_d_input_frame = cv2.resize(\n",
    "            frame, dsize=(plate_d_width,plate_d_height), interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "        plate_d_frame_rgb = cv2.cvtColor(plate_d_input_frame, cv2.COLOR_BGR2RGB)\n",
    "        #create batch of images\n",
    "        plate_d_input_frame = np.expand_dims(plate_d_input_frame, axis=0)\n",
    "        \n",
    "                   \n",
    "        #measure processing time\n",
    "        t1 = time.time()\n",
    "        #get detections\n",
    "        #results = compiled_model([input_frame])[output_layer]\n",
    "        plate_d_results = compiled_plate_d_model([plate_d_input_frame])[plate_d_output_layer]\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # get poses from person, vehicle, bike detection results\n",
    "#         boxes = process_results(frame=frame, results=results, thresh=THRESH)\n",
    "#         # draw bboxes\n",
    "#         frame = draw_boxes(detection='PVB', frame=frame, boxes=boxes)\n",
    "        \n",
    "        #get poses from plate number detection results\n",
    "        plate_d_boxes = process_results(frame=frame, results=plate_d_results, thresh=THRESH)\n",
    "        # draw bboxes\n",
    "        frame = draw_boxes(detection_type='LP', frame=frame, boxes=plate_d_boxes)\n",
    "\n",
    "        # size of the original frame\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        #create lists for prediction results\n",
    "        labels = []\n",
    "        scores = []\n",
    "        bboxes = []\n",
    "        for label, score, box in plate_d_boxes:\n",
    "            label = label-1\n",
    "            labels.append(label)\n",
    "            scores.append(score)\n",
    "            bboxes.append(list(np.array(box)))\n",
    "        \n",
    "        names = []\n",
    "        for i in range(len(labels)):\n",
    "            names.append(classes[int(labels[i])])\n",
    "        names = np.array(names)\n",
    "        \n",
    "        features = encoder(frame, bboxes)\n",
    "        detections = [Detection(bbox, score, name, feature) for bbox, score, name, feature\n",
    "                     in zip(bboxes, scores, names, features)]\n",
    "        \n",
    "        #detections can now be used for DeepSORT since NMS was used to eliminate duplication of the same target\n",
    "        tracker.predict() #uses Kalman filtering\n",
    "        tracker.update(detections) #updates the Kalman tracker parameters and filter\n",
    "        \n",
    "        person_current_count = int(0) #detect current vehicle in specific zone\n",
    "        vehicle_current_count = int(0) #detect current vehicles in specific zone\n",
    "        \n",
    "        #show tracked objects\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1: #if Kalman filtering was not able to assign a track\n",
    "                continue\n",
    "        \n",
    "            bbox = track.to_tlbr() #for OpenCV output minX, minY, maxX, maxY\n",
    "            class_name = track.get_class() #get the corresponding classes\n",
    "\n",
    "            center = (int(((bbox[0]) + (bbox[2]))/2), int(((bbox[1]) + (bbox[3]))/2)) #get center coordinates of bounding box\n",
    "            \n",
    "            #display text and circle relating to the tracked object\n",
    "            cv2.putText(\n",
    "                frame, \"ID {}\".format(track.track_id),\n",
    "                (center[0]-10, center[1]-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2\n",
    "            )\n",
    "            cv2.circle(frame, (center[0],center[1]), 4, (0,255,0), -1)\n",
    "            \n",
    "            #for counting\n",
    "            h, w, _ = frame.shape\n",
    "            \n",
    "            if center[1] <= h and center[1] >= 0 and center[0] >= 0 and center[0] <= w:\n",
    "                if class_name == classes[0]: #if detected class is a person\n",
    "                    if int(track.track_id) not in person_counter:\n",
    "                        person_counter.append(int(track.track_id))\n",
    "                    person_current_count += 1\n",
    "                elif class_name in classes[1:]: #if detected class is a vehicle or bike\n",
    "                    if int(track.track_id) not in vehicle_counter:\n",
    "                        vehicle_counter.append(int(track.track_id))\n",
    "                    vehicle_current_count += 1\n",
    "            \n",
    "        #display persons count\n",
    "        person_total_count = len(set(person_counter))\n",
    "        person_total_count_hour = len(set(person_counter)) - prev_hours_person_count\n",
    "        cv2.putText(frame, \"Current Persons in Frame: \" + str(person_current_count), (0,130), 0, 1, (0,255,0),2)\n",
    "        cv2.putText(frame, \"Total Persons Detected This Hour: \" + str(person_total_count_hour), (0,280), 0, 1, (0,255,0),2)\n",
    "        cv2.putText(frame, \"Total Persons Detected: \" + str(person_total_count), (0,430), 0, 1, (0,255,0),2)\n",
    "\n",
    "        #display vehicle count\n",
    "        vehicle_total_count = len(set(vehicle_counter))\n",
    "        vehicle_total_count_hour = len(set(vehicle_counter)) - prev_hours_vehicle_count\n",
    "        cv2.putText(frame, \"Current Vehicles in Frame: \" + str(vehicle_current_count), (0,180), 0, 1, (0,255,0),2)\n",
    "        cv2.putText(frame, \"Total Vehicles Detected This Hour: \" + str(vehicle_total_count_hour), (0,330), 0, 1, (0,255,0),2)\n",
    "        cv2.putText(frame, \"Total Vehicles Detected: \" + str(vehicle_total_count), (0,480), 0, 1, (0,255,0),2)\n",
    "    \n",
    "        processing_times.append(t1 - t2)\n",
    "        #use processing times from last 200 frames\n",
    "        if len(processing_times) > 200:\n",
    "            processing_times.popleft()\n",
    "            \n",
    "        _, f_width = frame.shape[:2]\n",
    "        # get mean processing time [ms]\n",
    "        processing_time = np.mean(processing_times) * 1000\n",
    "        #get fps\n",
    "        fps = 1000 / processing_time\n",
    "        #display fps\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            f\"Inference Time: {processing_time:.1f}ms ({fps:.1f} FPS)\",\n",
    "            (20, 40),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            f_width / 1000,\n",
    "            (0,0,255),\n",
    "            1,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        #display date and time\n",
    "        current_time = time.asctime( time.localtime(time.time()) )\n",
    "        cv2.putText(frame, current_time, (0,80), 0, 1, (255,255,255), 2)\n",
    "\n",
    "        #Save count every hour\n",
    "        if ( (time.localtime(time.time()).tm_min % 1 == 0) and (time.localtime(time.time()).tm_min == 0) and (time.localtime(time.time()).tm_sec == 0) ):\n",
    "            #append to dictionary\n",
    "            date_time_split = current_time.split()\n",
    "            count_dict['Total Persons'].append(person_total_count_hour)\n",
    "            count_dict['Total Vehicles'].append(vehicle_total_count_hour)\n",
    "            count_dict['Day'].append(date_time_split[0])\n",
    "            count_dict['Date'].append(date_time_split[2] + \" \" + date_time_split[1] + \" \" + date_time_split[4])\n",
    "            count_dict['Time'].append(date_time_split[3])\n",
    "\n",
    "            #form dataframe\n",
    "            df = pd.DataFrame(count_dict)\n",
    "\n",
    "            #save dataframe to CSV file\n",
    "            df.to_csv('Person and Vehicle Count (Per Hour).csv')\n",
    "            print('Saved Count Data for ' + current_time)\n",
    "\n",
    "            #reset total person and vehicle count\n",
    "            prev_hours_person_count = person_total_count\n",
    "            prev_hours_vehicle_count = vehicle_total_count\n",
    "        \n",
    "        #display video stream\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): #press Q to quit\n",
    "            break\n",
    "\n",
    "    #clear stream capture\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2d4439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-6e7c01320c89>:170: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  fps = 1000 / processing_time\n"
     ]
    }
   ],
   "source": [
    "video_path = './data/video/Megaworld CCTV/5_6337009788940977940.avi'\n",
    "detect(source=video_path, flip=True, use_popup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00d495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
