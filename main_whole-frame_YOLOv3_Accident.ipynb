{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad71f081",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb13b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For command line use of YOLOv3 (required)\n",
    "import collections\n",
    "from collections import deque\n",
    "from absl import flags\n",
    "import sys\n",
    "FLAGS = flags.FLAGS\n",
    "sys.argv = sys.argv[:1]\n",
    "FLAGS(sys.argv)\n",
    "\n",
    "#for writing data to a csv file\n",
    "import pandas as pd\n",
    "\n",
    "import time #for calculating FPS\n",
    "import math\n",
    "from math import isclose\n",
    "import numpy as np\n",
    "import cv2 #OpenCV\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#Use the GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "#Check if GPU is being used\n",
    "print(\"GPU: \", tf.test.is_gpu_available())\n",
    "\n",
    "#under yolov3_tf2 folder\n",
    "from yolov3_tf2.models import YoloV3\n",
    "from yolov3_tf2.dataset import transform_images #for data augmentation\n",
    "from yolov3_tf2.utils import convert_boxes, load_darknet_weights, preprocess_image #converts bboxes to deepsort format\n",
    "\n",
    "#for object tracking\n",
    "from deep_sort import preprocessing #for max suppressions\n",
    "from deep_sort import nn_matching #for setting up the association metrics\n",
    "from deep_sort.detection import Detection #for object detection\n",
    "from deep_sort.tracker import Tracker #for object tracking information\n",
    "from tools import generate_detections as gdet #feature generation encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad576a3",
   "metadata": {},
   "source": [
    "### Load YOLOv3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4cd091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define classes\n",
    "class_names = [c.strip() for c in open('./data/labels/coco.names').readlines()]\n",
    "\n",
    "#define allowed classes:\n",
    "allowed_classes = ['person', 'bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "vehicle_classes = ['bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "\n",
    "#define paths\n",
    "weightsyolov3 = './weights/yolov3.weights' # path to weights file\n",
    "weights= 'checkpoints/yolov3.tf' # path to checkpoints file\n",
    "size= 416             #resize images to\\\n",
    "checkpoints = 'checkpoints/yolov3.tf'\n",
    "num_classes = 80      # number of classes in the model\n",
    "\n",
    "#load model\n",
    "yolo = YoloV3(classes=num_classes)\n",
    "load_darknet_weights(yolo, weightsyolov3)\n",
    "yolo.save_weights(checkpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca0ae0d",
   "metadata": {},
   "source": [
    "### Load DeepSORT Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11fb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.2 #used to determine if objects between frames are the same\n",
    "nn_budget = None #used to form a gallery for storing of features\n",
    "nms_max_overlap = 0.5 #used to avoid too many detections on the same object\n",
    "\n",
    "model_filename = './model_data/mars-small128.pb' #pretrained CNN for pedestrian tracking\n",
    "encoder = gdet.create_box_encoder(model_filename, batch_size=8) #feature generations\n",
    "\n",
    "metric = nn_matching.NearestNeighborDistanceMetric('cosine', max_cosine_distance, nn_budget) #for measuring associations\n",
    "tracker = Tracker(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b040c7",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762abb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get intersection of two lines\n",
    "def line_intersection(line1, line2):\n",
    "    # Line 1 represented as a1x + b1y = c1\n",
    "    a1 = line1[1][1] - line1[0][1]\n",
    "    b1 = line1[0][0] - line1[1][0]\n",
    "    c1 = a1*(line1[0][0]) + b1*(line1[0][1])\n",
    " \n",
    "    # Line 2 represented as a2x + b2y = c2\n",
    "    a2 = line2[1][1] - line2[0][1]\n",
    "    b2 = line2[0][0] - line2[1][0]\n",
    "    c2 = a2*(line2[0][0]) + b2*(line2[0][1])\n",
    " \n",
    "    determinant = a1*b2 - a2*b1\n",
    " \n",
    "    if (determinant == 0):\n",
    "        x = 0\n",
    "        y = 0\n",
    "    else:\n",
    "        x = (b2*c1 - b1*c2)/determinant\n",
    "        y = (a1*c2 - a2*c1)/determinant\n",
    "    \n",
    "    return int(x), int(y)\n",
    "\n",
    "def get_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt( ((x2-x1)**2) + ((y2-y1)**2) )\n",
    "\n",
    "def pointIsOnLine(pt1,pt2,pt3):\n",
    "    x1, x2, x3 = pt1[0], pt2[0], pt3[0]\n",
    "    y1, y2, y3 = pt1[1], pt2[1], pt3[1]\n",
    "    \n",
    "    if x2-x1 != 0 and x3-x1 != 0:\n",
    "        slope = (y2-y1) / (x2-x1)\n",
    "    \n",
    "        pt3_on = isclose((y3-y1)/(x3-x1), slope, abs_tol=0.1)\n",
    "\n",
    "        pt3_between = (min(x1,x2) <= x3 <= max(x1,x2)) and (min(y1,y2) <= y3 <= max(y1,y2))\n",
    "        on_and_between = pt3_on and pt3_between\n",
    "        return on_and_between\n",
    "    \n",
    "    else:\n",
    "        pt3_between = (min(x1,x2) <= x3 <= max(x1,x2)) and (min(y1,y2) <= y3 <= max(y1,y2))\n",
    "        return pt3_between\n",
    "    \n",
    "def is_outlier(points):\n",
    "    \"\"\"\n",
    "    Returns a boolean array with True if points are outliers and False if otherwise\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "        points : Array of observations\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        mask : a boolean array\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    mean = np.mean(points, axis=0)\n",
    "    stdev = np.std(points, axis=0)\n",
    "    outliers = (np.abs(points-mean) > stdev)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83fb7f",
   "metadata": {},
   "source": [
    "### Track Using Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48562d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to select video\n",
    "# vid = cv2.VideoCapture('./data/video/Megaworld CCTV/megaworld_accident_1.MP4') #vehicles parallel to one another\n",
    "# vid = cv2.VideoCapture('./data/video/Megaworld CCTV/megaworld_accident_2.MP4') #camera is too far\n",
    "# vid = cv2.VideoCapture('./data/video/Megaworld CCTV/megaworld_accident_3.mp4') # megaworld night time (car and motorcycle)\n",
    "# vid = cv2.VideoCapture('./data/video/YouTube Accidents/youtube_accident_1.mp4') #india accident video\n",
    "# vid = cv2.VideoCapture('./data/video/YouTube Accidents/youtube_accident_2.mp4') #video with the best angle\n",
    "# vid = cv2.VideoCapture('./data/video/YouTube Accidents/youtube_accident_3.mp4') #Motorcycle and truck\n",
    "# vid = cv2.VideoCapture('./data/video/YouTube Accidents/youtube_accident_4.mp4') #improve trajectory\n",
    "\n",
    "#give video time to warm up\n",
    "time.sleep(0.1)\n",
    "\n",
    "processing_times = deque()\n",
    "\n",
    "#list for historical trajectory\n",
    "track_bboxes = [deque(maxlen=30) for _ in range(1000)]\n",
    "points = [deque(maxlen=30) for _ in range(1000)]\n",
    "next_points = [deque(maxlen=30) for _ in range(1000)]\n",
    "speeds = [deque(maxlen=30) for _ in range(1000)]\n",
    "accelerations = [deque(maxlen=30) for _ in range(1000)]\n",
    "jumps = [deque(maxlen=30) for _ in range(1000)]\n",
    "acc_anomaly_list = [deque(maxlen=30) for _ in range(1000)]\n",
    "\n",
    "track_ids = []\n",
    "overlap_list = []\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "overlap_anomaly = False\n",
    "acc_anomaly = False\n",
    "angle_anomaly = True\n",
    "collision = False\n",
    "\n",
    "#begin video capturing\n",
    "while (vid.isOpened()):\n",
    "    #capture frame\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    if frame is None:\n",
    "        print('Completed!')\n",
    "        break\n",
    "\n",
    "    #if frame is larger than full HD, reduce size to improve performance\n",
    "    scale = 1280 / max(frame.shape)\n",
    "    if scale < 1:\n",
    "        frame = cv2.resize(\n",
    "            src=frame,\n",
    "            dsize=None,\n",
    "            fx=scale,\n",
    "            fy=scale,\n",
    "            interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "        \n",
    "    # frame parameters\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "    \n",
    "    #preprocessing for YOLOv3 Input\n",
    "    frame_input = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) #video captured by OpenCV is in BGR format; tensorflow is RGB\n",
    "    frame_input = tf.expand_dims(frame_input, 0) #expands dims from C,H,W to N,C,H,W\n",
    "    frame_input = preprocess_image(frame_input, 416) #tensorflow shape is 416\n",
    "    \n",
    "    #start the timer\n",
    "    t1 = time.time() \n",
    "    \n",
    "    #Get object detection\n",
    "    bboxes, scores, classes, nums = yolo(frame_input)\n",
    "    \n",
    "    t2 = time.time()\n",
    "    \n",
    "    #maximum of 100 bboxes per image\n",
    "    #boxes: 3D shape (1, 100, 4); 100 max bboxes; 4 = x and y (center coordinates), width, height\n",
    "    #scores: 2D shape (1, 100); detected objects' confidence scores\n",
    "    #classes: 2D shape(1, 100); detected objects' classes\n",
    "    #nums: 1D shape (1); the total number of detected objects\n",
    "    #these variables are important for DeepSORT\n",
    "    \n",
    "    classes = classes[0]\n",
    "    names = []\n",
    "    for i in range(len(classes)):\n",
    "        names.append(class_names[int(classes[i])])\n",
    "    \n",
    "    names = np.array(names) #format for Non-Maximum Suppression (NMS)\n",
    "    numpy_bboxes = np.array(bboxes[0])\n",
    "    converted_bboxes = convert_boxes(frame, numpy_bboxes) #converts boxes into list\n",
    "    features = encoder(frame, converted_bboxes) #generate the feature spectra of the detected object\n",
    "    detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature \n",
    "                  in zip(converted_bboxes, scores[0], names, features)]\n",
    "    \n",
    "    #perform non-max suppression to eliminate multiple frames on one target\n",
    "    boxs = np.array([d.tlwh for d in detections])\n",
    "    scores = np.array([d.confidence for d in detections])\n",
    "    classes = np.array([d.class_name for d in detections])\n",
    "    indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores) #indices associate an object with a track\n",
    "    detections = [detections[i] for i in indices] #removes redundancies\n",
    "    \n",
    "    #detections can now be used for DeepSORT since NMS was used to eliminate duplication of the same target\n",
    "    tracker.predict() #uses Kalman filtering\n",
    "    tracker.update(detections) #updates the Kalman tracker parameters and filter\n",
    "    \n",
    "    cmap = plt.get_cmap('tab20b') #generate color maps\n",
    "    colors = [cmap(i)[:3] for i in np.linspace(0,1,20)] #generate 20 steps colors\n",
    "    \n",
    "    #show tracked objects\n",
    "    for track in tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1: #if Kalman filtering was not able to assign a track\n",
    "            continue\n",
    "        class_name = track.get_class() #get the corresponding classes\n",
    "        color = colors[int(track.track_id) % len(colors)] #assigning the color code\n",
    "        color = [i * 255 for i in color] #color originally ranges from 0 to 1; thus must be converted from 0 to 255\n",
    "        \n",
    "        if class_name in allowed_classes:\n",
    "            bbox = track.to_tlbr() #for OpenCV output minX, minY, maxX, maxY\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2) #bounding box rectangle\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1]-30)), \n",
    "                          (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, int(bbox[1])), color, -1) #rectangle for text\n",
    "            cv2.putText(frame, class_name + \" - \" + str(track.track_id), (int(bbox[0]), int(bbox[1]-10)), \n",
    "                        0, 0.75, (255,255,255), 2) #display text for class name and Tracking ID\n",
    "\n",
    "\n",
    "            center = (int(((bbox[0]) + (bbox[2]))/2), int(((bbox[1]) + (bbox[3]))/2)) #get center coordinates of bounding box\n",
    "            points[track.track_id].append(center)\n",
    "            \n",
    "            # get overlapping bounding boxes\n",
    "            for track2 in tracker.tracks:\n",
    "                class2_name = track2.get_class()\n",
    "                if class2_name in vehicle_classes:\n",
    "                    bbox2 = track2.to_tlbr()\n",
    "                    if track.track_id != track2.track_id:\n",
    "                            # first bbox\n",
    "                            x1_min = bbox[0]\n",
    "                            y1_min = bbox[1]\n",
    "                            x1_max = bbox[2]\n",
    "                            y1_max = bbox[3]\n",
    "                            # second bbox\n",
    "                            x2_min = bbox2[0]\n",
    "                            y2_min = bbox2[1]\n",
    "                            x2_max = bbox2[2]\n",
    "                            y2_max = bbox2[3]\n",
    "                            # check if the two are not the same detections\n",
    "                            center1 = (int(((x1_min) + (x1_max))/2), int(((y1_min) + (y1_max))/2)) \n",
    "                            center2 = (int(((x2_min) + (x2_max))/2), int(((y2_min) + (y2_max))/2))\n",
    "                            centroid_distance = get_distance(center1[0],center1[1],center2[0],center2[1])\n",
    "                            if centroid_distance > 50:\n",
    "                                # check for overlaps\n",
    "                                if (x1_min < x2_max and x2_min < x1_max) and (y1_min < y2_max and y2_min < y1_max):\n",
    "                                    overlap_anomaly = True\n",
    "                                    overlap_ids = tuple(sorted((track.track_id, track2.track_id)))\n",
    "                                    overlap_list.append(overlap_ids) #append overlapping vehicle ROIs to list\n",
    "                                    overlap_list = list(dict.fromkeys(overlap_list)) #remove duplicate tuples\n",
    "                                    #break\n",
    "                                else: \n",
    "                                    overlap_anomaly = False\n",
    "                    \n",
    "            #compute speed and append to list\n",
    "            start_point = points[track.track_id][0]\n",
    "            end_point = points[track.track_id][-1]\n",
    "            distance = (get_distance(start_point[0],start_point[1],end_point[0],end_point[1]) / end_point[1]) * 100\n",
    "            time_period = len(points[track.track_id])\n",
    "            speed = distance / time_period\n",
    "            speeds[track.track_id].append(speed)\n",
    "            cv2.putText(frame, \"{:.2f} units/frame\".format(speed), (int(bbox[0]), int(bbox[1]-30)), \n",
    "                        0, 0.75, (0,255,0), 2) #display text for speed of Tracking ID\n",
    "            \n",
    "            #compute acceleration\n",
    "            if len(speeds[track.track_id]) > 3: \n",
    "                current_speed = speeds[track.track_id][-1]\n",
    "                prev_speeds = [speeds[track.track_id][-4], speeds[track.track_id][-3], speeds[track.track_id][-2]]\n",
    "                avg_prev_speed = sum(prev_speeds) / len(prev_speeds)\n",
    "                acceleration = current_speed - avg_prev_speed\n",
    "                accelerations[track.track_id].append(acceleration)\n",
    "                \n",
    "            #get anomaly results\n",
    "            if len(accelerations[track.track_id]) > 3:\n",
    "                current_acc = accelerations[track.track_id][-1]\n",
    "                prev_accs = [accelerations[track.track_id][-4], accelerations[track.track_id][-3], accelerations[track.track_id][-2]]\n",
    "                avg_prev_acc = sum(prev_accs) / len(prev_accs)\n",
    "                jump = current_acc - avg_prev_acc\n",
    "                jumps[track.track_id].append(jump)\n",
    "                acc_anomaly_list[track.track_id] = is_outlier(np.array(jumps[track.track_id]))\n",
    "            \n",
    "            # get projected direction\n",
    "            if len(points[track.track_id]) > 3:\n",
    "                prev_x_points = [points[track.track_id][-4][0], points[track.track_id][-3][0], points[track.track_id][-2][0]]\n",
    "                prev_y_points = [points[track.track_id][-4][1], points[track.track_id][-3][1], points[track.track_id][-2][1]]\n",
    "                avg_x_points = sum(prev_x_points) / len(prev_x_points)\n",
    "                avg_y_points = sum(prev_y_points) / len(prev_y_points)\n",
    "                prev_point = (int(avg_x_points), int(avg_y_points))\n",
    "                delta_y = (end_point[1] - prev_point[1]) \n",
    "                delta_x = (end_point[0] - prev_point[0])\n",
    "                next_point = (end_point[0]+(delta_x*8),end_point[1]+(delta_y*8))\n",
    "                next_points[track.track_id].append(next_point)\n",
    "                cv2.arrowedLine(frame, (end_point), (next_point), (0,255,0), 2)\n",
    "            \n",
    "            # begin collision detection on overlapping objects\n",
    "            if  len(overlap_list)>0:\n",
    "                for overlap_objs in overlap_list:\n",
    "                    obj1 = overlap_objs[0]\n",
    "                    obj2 = overlap_objs[1]\n",
    "                    if len(points[obj1]) > 3 and len(points[obj2]) > 3:\n",
    "                        # get line coordinates of obj1\n",
    "                        obj1_curr_point = points[obj1][-1]\n",
    "                        obj1_next_point = next_points[obj1][-1]\n",
    "                        line1 = [obj1_curr_point, obj1_next_point]\n",
    "                        # get line coordinates of obj2\n",
    "                        obj2_curr_point = points[obj2][-1]\n",
    "                        obj2_next_point = next_points[obj2][-1]\n",
    "                        line2 = [obj2_curr_point, obj2_next_point]\n",
    "                        # get intersection of the two lines\n",
    "                        intersection = line_intersection(line1,line2)\n",
    "                        if (intersection[0] != 0 and intersection[1] != 0) and (intersection[0] != None and intersection[1] != None):\n",
    "                            # check if the intersection is on the trajectory line\n",
    "                            obj1_intersects = pointIsOnLine(obj1_curr_point, obj1_next_point, intersection)\n",
    "                            obj2_intersects = pointIsOnLine(obj2_curr_point, obj2_next_point, intersection)\n",
    "                            if (obj1_intersects and obj2_intersects):\n",
    "                                cv2.circle(frame, (intersection[0],intersection[1]), 10, (0,0,255), -1) #visualize intersection\n",
    "                                if len(speeds[obj1]) > 3 and len(speeds[obj2]) > 3: #minimum number of speed values for anomaly detection\n",
    "                                    if len(acc_anomaly_list[obj1]) > 1 and len(acc_anomaly_list[obj2]) > 1:\n",
    "                                        if acc_anomaly_list[obj1][-1] == True or acc_anomaly_list[obj2][-1] == True: #anomaly detected in acceleration\n",
    "                                            print(\"Anomaly of IDs {},{}: {} {}\".format(obj1,obj2,acc_anomaly_list[obj1][-1], acc_anomaly_list[obj2][-1]))\n",
    "                                            collision = True\n",
    "            \n",
    "            if collision == True:\n",
    "                cv2.rectangle(frame, (0,frame_height-80), (500, frame_height), (0,0,255), -1)\n",
    "                cv2.putText(frame, \"Collision Detected!\", (30, frame_height-30), 0, 1, (255,255,255), 2)\n",
    "            \n",
    "            #for historical trajectory\n",
    "            for j in range(1, len(points[track.track_id])):\n",
    "                if points[track.track_id][j-1] is None or points[track.track_id][j] is None: #check if current and previous tracker has a center point\n",
    "                    continue\n",
    "                thickness = int(np.sqrt(64/float(j+1))*2) #closer points are visually thinner\n",
    "                cv2.line(frame, (points[track.track_id][j-1]), (points[track.track_id][j]), color, thickness)\n",
    "\n",
    "    processing_times.append(t1 - t2)\n",
    "    #use processing times from last 200 frames\n",
    "    if len(processing_times) > 200:\n",
    "        processing_times.popleft()\n",
    "\n",
    "    _, f_width = frame.shape[:2]\n",
    "    # get mean processing time [ms]\n",
    "    processing_time = np.mean(processing_times) * 1000\n",
    "    #get fps\n",
    "    fps = 1000 / processing_time\n",
    "    #display fps\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Inference Time: {processing_time:.1f}ms ({fps:.1f} FPS)\",\n",
    "        (20, 40),\n",
    "        cv2.FONT_HERSHEY_COMPLEX,\n",
    "        f_width / 1000,\n",
    "        (0,0,255),\n",
    "        1,\n",
    "        cv2.LINE_AA\n",
    "    )\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    #display date and time\n",
    "    current_time = time.asctime( time.localtime(time.time()) )\n",
    "    cv2.putText(frame, current_time, (0,80), 0, 1, (255,255,255), 2)\n",
    "    \n",
    "    #display video stream\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #press Q to quit\n",
    "        break\n",
    "\n",
    "#clear stream capture\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78735443",
   "metadata": {},
   "source": [
    "### Plot Acceleration Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b77c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for vehicle_object_id in set(itertools.chain.from_iterable(overlap_list)):\n",
    "    speed_values = speeds[vehicle_object_id]\n",
    "    acc_values = accelerations[vehicle_object_id]\n",
    "    jump_values = jumps[vehicle_object_id]\n",
    "    anomaly_values = acc_anomaly_list[vehicle_object_id]\n",
    "    \n",
    "    plt.figure(figsize=(20,6), dpi=80)\n",
    "    \n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.plot(range(len(speed_values)), speed_values)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Speed')\n",
    "    plt.title('Speed of Vehicle ID {}'.format(vehicle_object_id))\n",
    "    \n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.plot(range(len(acc_values)), acc_values)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Acceleration')\n",
    "    plt.title('Acceleration of Vehicle ID {}'.format(vehicle_object_id))\n",
    "    \n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.plot(range(len(jump_values)), jump_values)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Jump in Acceleration')\n",
    "    plt.title('Jump in Acceleration of Vehicle ID {}'.format(vehicle_object_id))\n",
    "    \n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.plot(range(len(anomaly_values)), anomaly_values)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Anomaly Score')\n",
    "    plt.title('Anomaly Score of Vehicle ID {}'.format(vehicle_object_id))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8354a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dceef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
